{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos el excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar Recursos del Sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs disponibles: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 17:59:52.289018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-29 17:59:52.307118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-29 17:59:52.307261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"GPUs disponibles:\", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA está disponible. Número de GPUs: 1\n",
      "Nombre de la GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA está disponible. Número de GPUs:\", torch.cuda.device_count())\n",
    "    print(\"Nombre de la GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA no está disponible.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de CPUs (os.cpu_count()): 20\n",
      "Número de CPUs (multiprocessing.cpu_count()): 20\n",
      "CUDA está disponible. Número de GPUs: 1\n",
      "Nombre de la GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "GPUs disponibles en TensorFlow: 1\n",
      "Nombre de la GPU: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "def check_cpus():\n",
    "    print(\"Número de CPUs (os.cpu_count()):\", os.cpu_count())\n",
    "    print(\"Número de CPUs (multiprocessing.cpu_count()):\", multiprocessing.cpu_count())\n",
    "\n",
    "def check_gpu_pytorch():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA está disponible. Número de GPUs:\", torch.cuda.device_count())\n",
    "        print(\"Nombre de la GPU:\", torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        print(\"CUDA no está disponible en PyTorch.\")\n",
    "\n",
    "def check_gpu_tensorflow():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(\"GPUs disponibles en TensorFlow:\", len(gpus))\n",
    "        for gpu in gpus:\n",
    "            print(\"Nombre de la GPU:\", gpu.name)\n",
    "    else:\n",
    "        print(\"CUDA no está disponible en TensorFlow.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_cpus()\n",
    "    check_gpu_pytorch()\n",
    "    check_gpu_tensorflow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar y Preprocesar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto Original</th>\n",
       "      <th>Texto Corregido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>esto es importante para cada adulto o cada per...</td>\n",
       "      <td>Esto es importante para cada adulto o cada per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no salió todo como queríamos fue un buen año m...</td>\n",
       "      <td>No salió todo como queríamos, fue un buen año....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a lo largo de este top verás retratadas siete ...</td>\n",
       "      <td>A lo largo de este top verás retratadas siete ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>te prevengo querida audiencia los próximos min...</td>\n",
       "      <td>Te prevengo, querida audiencia, los próximos m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>número siete Benjamin Solari parravicini fue u...</td>\n",
       "      <td>Número siete: Benjamin Solari Parravicini fue ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Texto Original  \\\n",
       "0  esto es importante para cada adulto o cada per...   \n",
       "1  no salió todo como queríamos fue un buen año m...   \n",
       "2  a lo largo de este top verás retratadas siete ...   \n",
       "3  te prevengo querida audiencia los próximos min...   \n",
       "4  número siete Benjamin Solari parravicini fue u...   \n",
       "\n",
       "                                     Texto Corregido  \n",
       "0  Esto es importante para cada adulto o cada per...  \n",
       "1  No salió todo como queríamos, fue un buen año....  \n",
       "2  A lo largo de este top verás retratadas siete ...  \n",
       "3  Te prevengo, querida audiencia, los próximos m...  \n",
       "4  Número siete: Benjamin Solari Parravicini fue ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo Excel\n",
    "file_path = '/home/jovyan/work/transcripciones_frases_final.xlsx'\n",
    "\n",
    "# Cargamos el archivo Excel\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Verificar que las columnas existen\n",
    "assert 'Texto Original' in df.columns, \"La columna 'Texto Original' no existe en el archivo Excel\"\n",
    "assert 'Texto Corregido' in df.columns, \"La columna 'Texto Corregido' no existe en el archivo Excel\"\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir Datos en Entrenamiento y Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto Original</th>\n",
       "      <th>Texto Corregido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>Bueno, yo comencé a grabar ese video, le da un...</td>\n",
       "      <td>Bueno, yo comencé a grabar ese video, le di un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>ahora las cosas han cambiado con las redes soc...</td>\n",
       "      <td>Ahora las cosas han cambiado con las redes soc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>Vale ahora hacemos Dios Dios qué ven mis ojos ...</td>\n",
       "      <td>Vale, ahora hacemos... Dios. Dios. ¿Qué ven mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>Pues bueno otra las funciones de tener un VPN ...</td>\n",
       "      <td>Pues bueno, otra de las funciones de tener un ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>Por suerte nada más hicimos del número uno, si...</td>\n",
       "      <td>Por suerte nada más hicimos del número uno, si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Texto Original  \\\n",
       "785   Bueno, yo comencé a grabar ese video, le da un...   \n",
       "1355  ahora las cosas han cambiado con las redes soc...   \n",
       "528   Vale ahora hacemos Dios Dios qué ven mis ojos ...   \n",
       "1506  Pues bueno otra las funciones de tener un VPN ...   \n",
       "582   Por suerte nada más hicimos del número uno, si...   \n",
       "\n",
       "                                        Texto Corregido  \n",
       "785   Bueno, yo comencé a grabar ese video, le di un...  \n",
       "1355  Ahora las cosas han cambiado con las redes soc...  \n",
       "528   Vale, ahora hacemos... Dios. Dios. ¿Qué ven mi...  \n",
       "1506  Pues bueno, otra de las funciones de tener un ...  \n",
       "582   Por suerte nada más hicimos del número uno, si...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.15, random_state=42)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el Modelo y el Tokenizador\n",
    "\n",
    "Usaremos el modelos T5. Tokenizamos antes de introducir el texto en el modelo con T5Tokenizer \n",
    "Se puede usar 't5-base' o 't5-large' según lo preciso (más tiempo de entrenamiento) que queramos entrenar el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Cargar el tokenizador y el modelo\n",
    "model_name = 't5-small'  # Puedes usar 't5-small', 't5-base', 't5-large', etc.\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 0: corrija: Bueno, yo comencé a grabar ese video, le da un traguito a la copita, me sabía bien, pero no me caía bien.\n",
      "Target 0: Bueno, yo comencé a grabar ese video, le di un traguito a la copita, me sabía bien, pero no me caía bien.\n",
      "Input 1: corrija: ahora las cosas han cambiado con las redes sociales puesto que no hay una fuente de información única\n",
      "Target 1: Ahora las cosas han cambiado con las redes sociales, puesto que no hay una fuente de información única.\n",
      "Input 2: corrija: Vale ahora hacemos Dios Dios qué ven mis ojos qué ven mis ojos de momento no ven nada eso qué [ __ ] es vamos Azalea Azalea qué asco de bioma qué asco de bioma decepcionado Holden Holden no no per son este tipo de árboles eh\n",
      "Target 2: Vale, ahora hacemos... Dios. Dios. ¿Qué ven mis ojos? ¿Qué ven mis ojos? De momento no ven nada. ¿Eso qué es? Vamos. Azalea. Azalea. Qué asco de bioma. Qué asco de bioma. Decepcionado. Holden. Holden. No, no, pero son este tipo de árboles, eh.\n",
      "Input 3: corrija: Pues bueno otra las funciones de tener un VPN aparte lo que ya hemos hablado de la seguridad de la privacidad es poder hackear el sistema y comprar un vuelo un tren con los precios que realmente valen no como está jugando contigo el maldito página\n",
      "Target 3: Pues bueno, otra de las funciones de tener un VPN, aparte de lo que ya hemos hablado de la seguridad, de la privacidad, es poder hackear el sistema y comprar un vuelo o un tren con los precios que realmente valen, no como está jugando contigo la maldita página.\n",
      "Input 4: corrija: Por suerte nada más hicimos del número uno, si hubiéramos hecho el número dos, ahí tendríamos a una nutria flotando.\n",
      "Target 4: Por suerte nada más hicimos del número uno, si hubiéramos hecho el número dos, ahí tendríamos a una nutria flotando.\n",
      "Input 0: corrija: Se ha abierto la puerta. Ya está.\n",
      "Target 0: Se ha abierto la puerta. Ya está.\n",
      "Input 1: corrija: Si es que eres de esos que no ve la tele porque entonces lo harás con la tele si vas al trabajo o a la uni en metro será más de lo mismo.\n",
      "Target 1: Si es que eres de esos que no ve la tele porque entonces lo harás con la tele. Si vas al trabajo o a la uni en metro, será más de lo mismo.\n",
      "Input 2: corrija: Claro. Es lo que te dije. No tiene energía suficiente.\n",
      "Target 2: Claro. Es lo que te dije. No tiene energía suficiente.\n",
      "Input 3: corrija: por ahí también hay una foto creo que esto es en España que es en conmemoración del evento este de de viva 24\n",
      "Target 3: Por ahí también hay una foto, creo que esto es en España, que es en conmemoración del evento este de Europa Viva 24.\n",
      "Input 4: corrija: Okay. ¿Qué tenemos aquí? A ver. Vale.\n",
      "Target 4: Okay. ¿Qué tenemos aquí? A ver. Vale.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data, tokenizer, max_len=60):\n",
    "    inputs = [f\"corrija: {text}\" for text in data['Texto Original']]\n",
    "    targets = [text for text in data['Texto Corregido']]\n",
    "    \n",
    "    input_encodings = tokenizer(inputs, truncation=True, padding=True, max_length=max_len)\n",
    "    target_encodings = tokenizer(targets, truncation=True, padding=True, max_length=max_len)\n",
    "    \n",
    "    for i in range(5):  # Verificar los primeros 5 pares\n",
    "        print(f\"Input {i}: {inputs[i]}\")\n",
    "        print(f\"Target {i}: {targets[i]}\")\n",
    "        \n",
    "    return {\n",
    "        'input_ids': input_encodings['input_ids'],\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids']\n",
    "    }\n",
    "\n",
    "train_encodings = preprocess_data(train_df, tokenizer)\n",
    "val_encodings = preprocess_data(val_df, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear Dataset para PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextCorrectionDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx], dtype=torch.long) for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "train_dataset = TextCorrectionDataset(train_encodings)\n",
    "val_dataset = TextCorrectionDataset(val_encodings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurar y Entrenar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1867' max='1867' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1867/1867 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.489900</td>\n",
       "      <td>0.397332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1867, training_loss=0.9228888145409999, metrics={'train_runtime': 168.9885, 'train_samples_per_second': 11.048, 'train_steps_per_second': 11.048, 'total_flos': 29611305861120.0, 'train_loss': 0.9228888145409999, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/home/jovyan/results',  # Directorio de salida\n",
    "    num_train_epochs=1,                 # Épocas\n",
    "    per_device_train_batch_size=1,      # Tamaño del lote de entrenamiento\n",
    "    per_device_eval_batch_size=1,       # Tamaño del lote de evaluación\n",
    "    warmup_steps=500,                   # Pasos de calentamiento\n",
    "    weight_decay=0.01,                  # Desintegración del peso\n",
    "    logging_dir='/home/jovyan/logs',    # Directorio de logs\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\",                   # Evitar el logging a WandB\n",
    "    fp16=True                           # Entrenamiento en punto flotante de 16 bits\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar Predicciones y Evaluar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def generate_predictions(model, tokenizer, dataset, max_length=60, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for i in range(len(dataset)):\n",
    "        inputs = tokenizer(dataset[i]['Texto Original'], return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}  # Mover los tensores a la GPU si está disponible\n",
    "        outputs = model.generate(inputs['input_ids'], max_length=max_length, num_beams=4, early_stopping=True)\n",
    "        pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        predictions.append(pred_text)\n",
    "    return predictions\n",
    "\n",
    "# Generar predicciones para el conjunto de validación\n",
    "val_predictions = generate_predictions(model, tokenizer, val_df.to_dict(orient='records'))\n",
    "\n",
    "# Métricas de evaluación\n",
    "rouge = load_metric('rouge')\n",
    "bleu = load_metric('bleu')\n",
    "\n",
    "# Preparar referencias y predicciones para evaluación\n",
    "references = val_df['Texto Corregido'].tolist()\n",
    "\n",
    "# Calcular métricas\n",
    "rouge_score = rouge.compute(predictions=val_predictions, references=references)\n",
    "bleu_score = bleu.compute(predictions=[pred.split() for pred in val_predictions],\n",
    "                          references=[[ref.split()] for ref in references])\n",
    "\n",
    "print(\"ROUGE score:\", rouge_score)\n",
    "print(\"BLEU score:\", bleu_score)\n",
    "\n",
    "# Para métricas de clasificación\n",
    "predicted_labels = [pred.split()[0] for pred in val_predictions]  # Ajusta según tu caso\n",
    "true_labels = val_df['Texto Corregido'].tolist()\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear y Visualizar la Matriz de Confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Convertir a etiquetas binarias (correcto/incorrecto)\n",
    "true_labels_binary = [1 if true == pred else 0 for true, pred in zip(true_labels, val_predictions)]\n",
    "predicted_labels_binary = [1 if true == pred else 0 for true, pred in zip(true_labels, val_predictions)]\n",
    "\n",
    "# Crear la matriz de confusión\n",
    "cm = confusion_matrix(true_labels_binary, predicted_labels_binary, labels=[1, 0])\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=[\"Correcto\", \"Incorrecto\"])\n",
    "\n",
    "# Graficar la matriz de confusión\n",
    "cmd.plot()\n",
    "plt.title(\"Matriz de Confusión - Corrección de Texto\")\n",
    "plt.xlabel(\"Etiqueta Predicha\")\n",
    "plt.ylabel(\"Etiqueta Verdadera\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
