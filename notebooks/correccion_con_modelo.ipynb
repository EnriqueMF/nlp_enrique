{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos el excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar Recursos del Sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs disponibles: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 17:59:52.289018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-29 17:59:52.307118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-29 17:59:52.307261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"GPUs disponibles:\", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA est√° disponible. N√∫mero de GPUs: 1\n",
      "Nombre de la GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA est√° disponible. N√∫mero de GPUs:\", torch.cuda.device_count())\n",
    "    print(\"Nombre de la GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA no est√° disponible.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de CPUs (os.cpu_count()): 20\n",
      "N√∫mero de CPUs (multiprocessing.cpu_count()): 20\n",
      "CUDA est√° disponible. N√∫mero de GPUs: 1\n",
      "Nombre de la GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "GPUs disponibles en TensorFlow: 1\n",
      "Nombre de la GPU: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "def check_cpus():\n",
    "    print(\"N√∫mero de CPUs (os.cpu_count()):\", os.cpu_count())\n",
    "    print(\"N√∫mero de CPUs (multiprocessing.cpu_count()):\", multiprocessing.cpu_count())\n",
    "\n",
    "def check_gpu_pytorch():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA est√° disponible. N√∫mero de GPUs:\", torch.cuda.device_count())\n",
    "        print(\"Nombre de la GPU:\", torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        print(\"CUDA no est√° disponible en PyTorch.\")\n",
    "\n",
    "def check_gpu_tensorflow():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(\"GPUs disponibles en TensorFlow:\", len(gpus))\n",
    "        for gpu in gpus:\n",
    "            print(\"Nombre de la GPU:\", gpu.name)\n",
    "    else:\n",
    "        print(\"CUDA no est√° disponible en TensorFlow.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_cpus()\n",
    "    check_gpu_pytorch()\n",
    "    check_gpu_tensorflow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar y Preprocesar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto Original</th>\n",
       "      <th>Texto Corregido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>esto es importante para cada adulto o cada per...</td>\n",
       "      <td>Esto es importante para cada adulto o cada per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no sali√≥ todo como quer√≠amos fue un buen a√±o m...</td>\n",
       "      <td>No sali√≥ todo como quer√≠amos, fue un buen a√±o....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a lo largo de este top ver√°s retratadas siete ...</td>\n",
       "      <td>A lo largo de este top ver√°s retratadas siete ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>te prevengo querida audiencia los pr√≥ximos min...</td>\n",
       "      <td>Te prevengo, querida audiencia, los pr√≥ximos m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n√∫mero siete Benjamin Solari parravicini fue u...</td>\n",
       "      <td>N√∫mero siete: Benjamin Solari Parravicini fue ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Texto Original  \\\n",
       "0  esto es importante para cada adulto o cada per...   \n",
       "1  no sali√≥ todo como quer√≠amos fue un buen a√±o m...   \n",
       "2  a lo largo de este top ver√°s retratadas siete ...   \n",
       "3  te prevengo querida audiencia los pr√≥ximos min...   \n",
       "4  n√∫mero siete Benjamin Solari parravicini fue u...   \n",
       "\n",
       "                                     Texto Corregido  \n",
       "0  Esto es importante para cada adulto o cada per...  \n",
       "1  No sali√≥ todo como quer√≠amos, fue un buen a√±o....  \n",
       "2  A lo largo de este top ver√°s retratadas siete ...  \n",
       "3  Te prevengo, querida audiencia, los pr√≥ximos m...  \n",
       "4  N√∫mero siete: Benjamin Solari Parravicini fue ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo Excel\n",
    "file_path = '/home/jovyan/work/transcripciones_frases_final.xlsx'\n",
    "\n",
    "# Cargamos el archivo Excel\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Verificar que las columnas existen\n",
    "assert 'Texto Original' in df.columns, \"La columna 'Texto Original' no existe en el archivo Excel\"\n",
    "assert 'Texto Corregido' in df.columns, \"La columna 'Texto Corregido' no existe en el archivo Excel\"\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir Datos en Entrenamiento y Validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texto Original</th>\n",
       "      <th>Texto Corregido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>Bueno, yo comenc√© a grabar ese video, le da un...</td>\n",
       "      <td>Bueno, yo comenc√© a grabar ese video, le di un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>ahora las cosas han cambiado con las redes soc...</td>\n",
       "      <td>Ahora las cosas han cambiado con las redes soc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>Vale ahora hacemos Dios Dios qu√© ven mis ojos ...</td>\n",
       "      <td>Vale, ahora hacemos... Dios. Dios. ¬øQu√© ven mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>Pues bueno otra las funciones de tener un VPN ...</td>\n",
       "      <td>Pues bueno, otra de las funciones de tener un ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>Por suerte nada m√°s hicimos del n√∫mero uno, si...</td>\n",
       "      <td>Por suerte nada m√°s hicimos del n√∫mero uno, si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Texto Original  \\\n",
       "785   Bueno, yo comenc√© a grabar ese video, le da un...   \n",
       "1355  ahora las cosas han cambiado con las redes soc...   \n",
       "528   Vale ahora hacemos Dios Dios qu√© ven mis ojos ...   \n",
       "1506  Pues bueno otra las funciones de tener un VPN ...   \n",
       "582   Por suerte nada m√°s hicimos del n√∫mero uno, si...   \n",
       "\n",
       "                                        Texto Corregido  \n",
       "785   Bueno, yo comenc√© a grabar ese video, le di un...  \n",
       "1355  Ahora las cosas han cambiado con las redes soc...  \n",
       "528   Vale, ahora hacemos... Dios. Dios. ¬øQu√© ven mi...  \n",
       "1506  Pues bueno, otra de las funciones de tener un ...  \n",
       "582   Por suerte nada m√°s hicimos del n√∫mero uno, si...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.15, random_state=42)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar el Modelo y el Tokenizador\n",
    "\n",
    "Usaremos el modelos T5. Tokenizamos antes de introducir el texto en el modelo con T5Tokenizer \n",
    "Se puede usar 't5-base' o 't5-large' seg√∫n lo preciso (m√°s tiempo de entrenamiento) que queramos entrenar el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Cargar el tokenizador y el modelo\n",
    "model_name = 't5-small'  # Puedes usar 't5-small', 't5-base', 't5-large', etc.\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 0: corrija: Bueno, yo comenc√© a grabar ese video, le da un traguito a la copita, me sab√≠a bien, pero no me ca√≠a bien.\n",
      "Target 0: Bueno, yo comenc√© a grabar ese video, le di un traguito a la copita, me sab√≠a bien, pero no me ca√≠a bien.\n",
      "Input 1: corrija: ahora las cosas han cambiado con las redes sociales puesto que no hay una fuente de informaci√≥n √∫nica\n",
      "Target 1: Ahora las cosas han cambiado con las redes sociales, puesto que no hay una fuente de informaci√≥n √∫nica.\n",
      "Input 2: corrija: Vale ahora hacemos Dios Dios qu√© ven mis ojos qu√© ven mis ojos de momento no ven nada eso qu√© [ __ ] es vamos Azalea Azalea qu√© asco de bioma qu√© asco de bioma decepcionado Holden Holden no no per son este tipo de √°rboles eh\n",
      "Target 2: Vale, ahora hacemos... Dios. Dios. ¬øQu√© ven mis ojos? ¬øQu√© ven mis ojos? De momento no ven nada. ¬øEso qu√© es? Vamos. Azalea. Azalea. Qu√© asco de bioma. Qu√© asco de bioma. Decepcionado. Holden. Holden. No, no, pero son este tipo de √°rboles, eh.\n",
      "Input 3: corrija: Pues bueno otra las funciones de tener un VPN aparte lo que ya hemos hablado de la seguridad de la privacidad es poder hackear el sistema y comprar un vuelo un tren con los precios que realmente valen no como est√° jugando contigo el maldito p√°gina\n",
      "Target 3: Pues bueno, otra de las funciones de tener un VPN, aparte de lo que ya hemos hablado de la seguridad, de la privacidad, es poder hackear el sistema y comprar un vuelo o un tren con los precios que realmente valen, no como est√° jugando contigo la maldita p√°gina.\n",
      "Input 4: corrija: Por suerte nada m√°s hicimos del n√∫mero uno, si hubi√©ramos hecho el n√∫mero dos, ah√≠ tendr√≠amos a una nutria flotando.\n",
      "Target 4: Por suerte nada m√°s hicimos del n√∫mero uno, si hubi√©ramos hecho el n√∫mero dos, ah√≠ tendr√≠amos a una nutria flotando.\n",
      "Input 0: corrija: Se ha abierto la puerta. Ya est√°.\n",
      "Target 0: Se ha abierto la puerta. Ya est√°.\n",
      "Input 1: corrija: Si es que eres de esos que no ve la tele porque entonces lo har√°s con la tele si vas al trabajo o a la uni en metro ser√° m√°s de lo mismo.\n",
      "Target 1: Si es que eres de esos que no ve la tele porque entonces lo har√°s con la tele. Si vas al trabajo o a la uni en metro, ser√° m√°s de lo mismo.\n",
      "Input 2: corrija: Claro. Es lo que te dije. No tiene energ√≠a suficiente.\n",
      "Target 2: Claro. Es lo que te dije. No tiene energ√≠a suficiente.\n",
      "Input 3: corrija: por ah√≠ tambi√©n hay una foto creo que esto es en Espa√±a que es en conmemoraci√≥n del evento este de de viva 24\n",
      "Target 3: Por ah√≠ tambi√©n hay una foto, creo que esto es en Espa√±a, que es en conmemoraci√≥n del evento este de Europa Viva 24.\n",
      "Input 4: corrija: Okay. ¬øQu√© tenemos aqu√≠? A ver. Vale.\n",
      "Target 4: Okay. ¬øQu√© tenemos aqu√≠? A ver. Vale.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data, tokenizer, max_len=60):\n",
    "    inputs = [f\"corrija: {text}\" for text in data['Texto Original']]\n",
    "    targets = [text for text in data['Texto Corregido']]\n",
    "    \n",
    "    input_encodings = tokenizer(inputs, truncation=True, padding=True, max_length=max_len)\n",
    "    target_encodings = tokenizer(targets, truncation=True, padding=True, max_length=max_len)\n",
    "    \n",
    "    for i in range(5):  # Verificar los primeros 5 pares\n",
    "        print(f\"Input {i}: {inputs[i]}\")\n",
    "        print(f\"Target {i}: {targets[i]}\")\n",
    "        \n",
    "    return {\n",
    "        'input_ids': input_encodings['input_ids'],\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids']\n",
    "    }\n",
    "\n",
    "train_encodings = preprocess_data(train_df, tokenizer)\n",
    "val_encodings = preprocess_data(val_df, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear Dataset para PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextCorrectionDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx], dtype=torch.long) for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "train_dataset = TextCorrectionDataset(train_encodings)\n",
    "val_dataset = TextCorrectionDataset(val_encodings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurar y Entrenar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1867' max='1867' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1867/1867 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.489900</td>\n",
       "      <td>0.397332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1867, training_loss=0.9228888145409999, metrics={'train_runtime': 168.9885, 'train_samples_per_second': 11.048, 'train_steps_per_second': 11.048, 'total_flos': 29611305861120.0, 'train_loss': 0.9228888145409999, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/home/jovyan/results',  # Directorio de salida\n",
    "    num_train_epochs=1,                 # √âpocas\n",
    "    per_device_train_batch_size=1,      # Tama√±o del lote de entrenamiento\n",
    "    per_device_eval_batch_size=1,       # Tama√±o del lote de evaluaci√≥n\n",
    "    warmup_steps=500,                   # Pasos de calentamiento\n",
    "    weight_decay=0.01,                  # Desintegraci√≥n del peso\n",
    "    logging_dir='/home/jovyan/logs',    # Directorio de logs\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\",                   # Evitar el logging a WandB\n",
    "    fp16=True                           # Entrenamiento en punto flotante de 16 bits\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar Predicciones y Evaluar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_metric\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def generate_predictions(model, tokenizer, dataset, max_length=60, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for i in range(len(dataset)):\n",
    "        inputs = tokenizer(dataset[i]['Texto Original'], return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}  # Mover los tensores a la GPU si est√° disponible\n",
    "        outputs = model.generate(inputs['input_ids'], max_length=max_length, num_beams=4, early_stopping=True)\n",
    "        pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        predictions.append(pred_text)\n",
    "    return predictions\n",
    "\n",
    "# Generar predicciones para el conjunto de validaci√≥n\n",
    "val_predictions = generate_predictions(model, tokenizer, val_df.to_dict(orient='records'))\n",
    "\n",
    "# M√©tricas de evaluaci√≥n\n",
    "rouge = load_metric('rouge')\n",
    "bleu = load_metric('bleu')\n",
    "\n",
    "# Preparar referencias y predicciones para evaluaci√≥n\n",
    "references = val_df['Texto Corregido'].tolist()\n",
    "\n",
    "# Calcular m√©tricas\n",
    "rouge_score = rouge.compute(predictions=val_predictions, references=references)\n",
    "bleu_score = bleu.compute(predictions=[pred.split() for pred in val_predictions],\n",
    "                          references=[[ref.split()] for ref in references])\n",
    "\n",
    "print(\"ROUGE score:\", rouge_score)\n",
    "print(\"BLEU score:\", bleu_score)\n",
    "\n",
    "# Para m√©tricas de clasificaci√≥n\n",
    "predicted_labels = [pred.split()[0] for pred in val_predictions]  # Ajusta seg√∫n tu caso\n",
    "true_labels = val_df['Texto Corregido'].tolist()\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear y Visualizar la Matriz de Confusi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Convertir a etiquetas binarias (correcto/incorrecto)\n",
    "true_labels_binary = [1 if true == pred else 0 for true, pred in zip(true_labels, val_predictions)]\n",
    "predicted_labels_binary = [1 if true == pred else 0 for true, pred in zip(true_labels, val_predictions)]\n",
    "\n",
    "# Crear la matriz de confusi√≥n\n",
    "cm = confusion_matrix(true_labels_binary, predicted_labels_binary, labels=[1, 0])\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=[\"Correcto\", \"Incorrecto\"])\n",
    "\n",
    "# Graficar la matriz de confusi√≥n\n",
    "cmd.plot()\n",
    "plt.title(\"Matriz de Confusi√≥n - Correcci√≥n de Texto\")\n",
    "plt.xlabel(\"Etiqueta Predicha\")\n",
    "plt.ylabel(\"Etiqueta Verdadera\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
